{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project instructions\n",
    "\n",
    "Final projects are due by **11:59 PM 22 Nov, 2021**.\n",
    "\n",
    "**Note**: You are free to revise *any* of the entries below, so don't be constrained by what you wrote if it does not work out. For example, you might change the data science objective, change the technology stack used, etc - if doing so would improve the project outcome.\n",
    "\n",
    "The dates given below are guides, but evidence of regular, incremental progress on the project will be considered in the final grade.\n",
    "\n",
    "Each group will be asked to make class presentations on their project between 15-22 Nov 2021.\n",
    "\n",
    "### Suggested timeline\n",
    "          \n",
    "#### Start by 27 Sep - 8 weeks before deadline\n",
    "\n",
    "- Form a team\n",
    "    - Give your team a name\n",
    "    - Form a team GitHub repository for your project \n",
    "        - you will write your own blog about the project on your individual GitHub-pages, but refer to the group repository for project content\n",
    "    - List members of your team and program on the README page\n",
    "    - Send Cliburn and Michale the following information:\n",
    "        - URL of team GitHUb repository\n",
    "        - Team name\n",
    "        - Name, email and program of each team member\n",
    "        - Which of the 3 data sets you will be working on\n",
    "    - Set up a channel for team communication on Teams/Slack/Sakai\n",
    "    - Set up schedule for team meetings\n",
    "    \n",
    "- The team repository README should contain the following\n",
    "    - The specific data sets you will be working with\n",
    "    - The objective of the project and how it benefits the target consumer\n",
    "        - What is the data product(s) that will be generated? For example, the project can generate one or more of the following\n",
    "            - Report (e.g. auto-generated PDF)\n",
    "            - Dashboard\n",
    "            - Online ML algorithm\n",
    "            - App\n",
    "            - Other\n",
    "    - A sketch of the data science plan, which may include (if appropriate)\n",
    "        - Data plan (Extract, Load, Transform)\n",
    "        - ML plan (Model training, evaluation, selection, deployment, monitoring)\n",
    "        - Operations plan (workflow orchestration, CI/CD, containerization, serverless, testing, packaging, logging)\n",
    "        - Technology stack (databases, python packages, cloud platform)\n",
    "    - Roles, responsibilities and *timed milestones* for each team member\n",
    "        - Plan for *accountability* but be willing to help out team members\n",
    "        - Ask team members for help if you are overwhelmed\n",
    "        \n",
    "- Do the research and necessary work as planned\n",
    "- Perform a branch and merge operation to fix a bug or add a feature\n",
    "- Contribute something to another team's project by forking and submitting a pull request\n",
    "\n",
    "**Make sure you review progress at the end of each week**\n",
    "\n",
    "#### 8 Nov 2021 - 2 weeks before deadline\n",
    "\n",
    "- Generate and review data product\n",
    "- Final optimizations\n",
    "- Revise team project README page\n",
    "- Write personal blog\n",
    "- Prepare for class presentation\n",
    "\n",
    "#### 22 Nov 2021\n",
    "\n",
    "- Final project due"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to see how much time you have left!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 3 months before proejct submission deadline.\n"
     ]
    }
   ],
   "source": [
    "import pendulum\n",
    "\n",
    "deadline = pendulum.datetime(2021, 11, 22, 11, 59, 59,tz='US/Eastern')\n",
    "print(f'You have {pendulum.now().diff_for_humans(deadline)} proejct submission deadline.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project instructions\n",
    "\n",
    "For the final project, you will choose a data set(s) from the following topics\n",
    "\n",
    "- COVID-19\n",
    "- ICU admission\n",
    "- UK BioBank\n",
    "\n",
    "From a team of 3-4 people. Each team will need to do the following:\n",
    "\n",
    "- Identify and frame data science problem to solve given the data (data analyst/domain expert)\n",
    "- Process and manage the data so that it is easily accessible (data engineer)\n",
    "- Develop the analysis, modeling and reporting data product (data scientist / machine learning engineer)\n",
    "\n",
    "Each group member will also have to do the following *individual* task:\n",
    "\n",
    "- Write a post on GitHub-pages about the project and what you learned from doing this\n",
    "\n",
    "**Note**: 80% of the grade will be based on the quality of the project as a whole (team effort); 20% will be based on teh quality of the blog/report (individual effort).\n",
    "\n",
    "### You should use the project to showcase the following skill sets\n",
    "\n",
    "- Basic skills\n",
    "    - Effective use of version control\n",
    "        - Ideally, showcase branch and merge skills for concurrent feature development / bug fixes\n",
    "    - Literate programming\n",
    "    - Functional coding style\n",
    "- Domain knowledge\n",
    "    - Introduction of domain concepts necessary to understand the data set(s)\n",
    "    - Framing the data science challenge\n",
    "- Data management\n",
    "    - Use of different data formats\n",
    "    - Use of SQL and/or NoSQL databases\n",
    "- Data analysis and visualization\n",
    "    - Data cleaning and validation\n",
    "    - Use of linked data sources if applicable\n",
    "    - Attractive and easy-to-understand reports and/or dashboards\n",
    "- Development of data product\n",
    "    - This is often a predictive machine learning model (classical or deep)\n",
    "        - Construct pipeline, perform model training, evaluation and selection\n",
    "    - Other data products can also be developed (in place of or in addition to supervised learning) if more appropriate for your problem\n",
    "        - Examples - unsupervised or self-supervised models, graphical models, complex interactive visualizations\n",
    "- Operationalization\n",
    "    - Testing, logging, monitoring, streaming, packaging if applicable\n",
    "    - Use of distributed computing platform if applicable\n",
    "    - Deployment to cloud platform (including serverless if applicable)\n",
    "    \n",
    "### Milestones\n",
    "\n",
    "- Form team (diversity is essential - teams **must** consist of people from at least 2 different programs)\n",
    "- Initial exploration of data sets for all topics\n",
    "- Choose topic\n",
    "- Further exploration of data sets for selected topic\n",
    "- Frame data science problem to solve\n",
    "- Develop the data science and machine learning product\n",
    "- Deploy the product to a cloud platform (GCP, Azure, AWS)\n",
    "- Streamline and automate \n",
    "\n",
    "\n",
    "### Suggestions for working as a team\n",
    "\n",
    "- You should begin as soon as possible\n",
    "- Aim to have a group meeting at least 1-2 times a week\n",
    "- Set up Teams or Slack for communication within your team\n",
    "- Probably easiest if someone takes the role of project manager to \n",
    "    - coordinate group activities \n",
    "    - check that sufficient progress is being made week-by-week.\n",
    "- Avoid excessive \"divide and conquer\" specialization\n",
    "    - individual should take on at least two roles\n",
    "    - each skill set area should have at least two people involved\n",
    "    - teach your team members how you performed a task that not everyone is familiar with\n",
    "\n",
    "## Data resources\n",
    "\n",
    "Your primary data source should be from one of these three links provided. You can, however, link to other public reference data sets, databases or ontologies if appropriate.\n",
    "\n",
    "**Notes** \n",
    "\n",
    "- To access the data set, you may need to register on the site, or even complete specified training courses.\n",
    "- If you need the data sets put on the Duke Spark cluster, please let me know and we will work with OIT to make this possible\n",
    "\n",
    "### [Open-Access Data and Computational Resources to Address COVID-19](https://datascience.nih.gov/covid-19-open-access-resources)\n",
    "\n",
    "- This is a meta-collection with multiple data resources; you only need to use one but can choose to link more than one if you think that is helpful\n",
    "- From the official description\n",
    "> COVID-19 open-access data and computational resources are being provided by federal agencies, including NIH, public consortia, and private entities. These resources are freely available to researchers, and this page will be updated as more information becomes available. \n",
    "> The Office of Data Science Strategy seeks to provide the research community with links to open-access data, computational, and supporting resources. These resources are being aggregated and posted for scientific and public health interests. Inclusion of a resource on this list does not mean it has been evaluated or endorsed by NIH.\n",
    "\n",
    "### [MIMIC ](https://mimic.physionet.org)\n",
    "\n",
    "- Deidentified health data associated with ~60,000 ICU admissions (53,432 adult patients and 8,100 neonatal patients) from June 2001 to October 2012\n",
    "- Includes demographics, vital signs, laboratory tests, medications, and more\n",
    "- You should start with the [demo data set](https://physionet.org/content/mimiciii-demo/1.4/) but eventuallly use the **full** data set for your final project\n",
    "- From official description\n",
    "> MIMIC-III is a large, freely-available database comprising deidentified health-related data associated with over 40,000 patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012 [1]. The MIMIC-III Clinical Database is available on PhysioNet (doi: 10.13026/C2XW26). Though deidentified, MIMIC-III contains detailed information regarding the care of real patients, and as such requires credentialing before access. To allow researchers to ascertain whether the database is suitable for their work, we have manually curated a demo subset, which contains information for 100 patients also present in the MIMIC-III Clinical Database. Notably, the demo dataset does not include free-text notes.\n",
    "\n",
    "\n",
    "### [UK BioBank](https://www.ukbiobank.ac.uk/)\n",
    "\n",
    "- From official description\n",
    "> UK Biobank is a large-scale biomedical database and research resource, containing in-depth genetic and health information from half a million UK participants. The database is regularly augmented with additional data and is globally accessible to approved researchers undertaking vital research into the most common and life-threatening diseases. It is a major contributor to the advancement of modern medicine and treatment and has enabled several scientific discoveries that improve human health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

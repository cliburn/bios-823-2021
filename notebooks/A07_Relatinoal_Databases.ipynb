{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Databases Overview\n",
    "\n",
    "For a simple tutorial on database design, see [Introduction to Database Design](https://www.datanamic.com/support/lt-dez005-introduction-db-modeling.html)\n",
    "\n",
    "For a deep dive, see [Database Design for Mere Mortals](https://www.amazon.com/Database-Design-Mere-Mortals-Hands/dp/0321884493/ref=dp_ob_title_bk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Packages for working with relational databases in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Python Database API Specification v2.0](https://www.python.org/dev/peps/pep-0249/) - The standard Python Database API\n",
    "- [sqlite3](https://docs.python.org/3.7/library/sqlite3.html) - API for builit-in `sqlite3` package\n",
    "- [Database drivers](https://github.com/vinta/awesome-python#database-drivers) - For connecting to other databases\n",
    "- [ipython-sql](https://github.com/catherinedevlin/ipython-sql) - SQL magic in Jupyter\n",
    "- [SQLAlchemy](https://www.sqlalchemy.org) - Most well-known Object Relational Mapper (ORM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why relational databases and SQL?\n",
    "\n",
    "- History of databases\n",
    "- ACID\n",
    "- Data integrity\n",
    "- Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDBMS\n",
    "\n",
    "- Memory\n",
    "- Storage\n",
    "- Dictionary\n",
    "- Query language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a database?\n",
    "\n",
    "A database contains tables with rows and columns. Tables belong to a schema. Schemas belong to a catalog. In other words, a database contains catalogs that contain schemas that contain tables (or views). Most simple database only consider the schema/table part of the hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema\n",
    "\n",
    "Represents a collection of tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table (Relation)\n",
    "\n",
    "There are two definitions of `relation` - in one, relation is a synonym for table, in the other, a relation describes how two tables are connected via foreign/primary keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represents a *subject* or an *event*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column (Attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represents a single *variable* or *feature*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row (Tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represents an *observation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints\n",
    "\n",
    "You can impose constraints that values in a column have to take. For example, you can specify that values are compulsory (NOT NULL), or UNIQUE or fall within a certain range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referential integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primary key represents a unique identifier of a row. It may be simple or composite.\n",
    "  - Unique\n",
    "  - Non-null\n",
    "  - Never optional\n",
    "- Foreign key is a column containing the primary key of a different table. It enforces *referential integrity*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One to one\n",
    "- One to many\n",
    "- Many to many\n",
    "\n",
    "- What happens on delete?\n",
    "  - Restrict\n",
    "  - Cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexes\n",
    "\n",
    "An index is a data structure that allows fast search of a column (typically from linear to log time complexity). Most databases will automatically build an index for every primary key column, but you can also manually specify columns to build indexes for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Temporary virtual table retuned as a result of a *query*.\n",
    "- Views only specify the strucutre of a table - the contents are constructed on the fly from existing tables.\n",
    "- Queries return a Result Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use singlular form for name \n",
    "- Use informative names\n",
    "- Use unique names not shared by any other table (except foreign keys)\n",
    "- Column must be an attribute of the table's subject\n",
    "- Eliminate multi-part columns\n",
    "- Eliminate multi-value columsn\n",
    "- Eliminate redundant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use singular/plural forms for name (controversial)\n",
    "- Enusre every table has a primary key\n",
    "- Eliminate duplicate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Establish participation type and degree of relationship\n",
    "  - One to one\n",
    "  - One to many\n",
    "  - Many to many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](erd_from_sqlalchemy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database administration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sqlmagic` as interface to `sqlite3` driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -m pip install --quiet ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to SQLite3 database on disk (creates it if it does not exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:///data/dummy.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL for table deletion and creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS Country;\n",
    "DROP TABLE IF EXISTS Person;\n",
    "\n",
    "CREATE TABLE Country (\n",
    "    country_id varcarh(2) PRIMARY KEY,\n",
    "    country_name varchar(255)\n",
    ");\n",
    "\n",
    "CREATE TABLE Person (\n",
    "    person_id INTEGER PRIMARY KEY,\n",
    "    person_first varchar(255),\n",
    "    person_last varchar(255),\n",
    "    country_id INTEGER NOT NULL,\n",
    "      FOREIGN KEY (country_id) REFERENCES Country(country_id)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the RDBMS data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT name FROM sqlite_master \n",
    "WHERE type = \"table\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT sql FROM sqlite_master \n",
    "WHERE name='Person';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRUD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create\n",
    "\n",
    "SQL to insert rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO Country(country_id, country_name) \n",
    "VALUES ('FR', 'France'), ('CU', 'CUBA');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO Person(person_first, person_last, country_id) \n",
    "VALUES \n",
    "('Napolean', 'Bonaparte', 'FR'),\n",
    "('Luis','Alvarez', 'CU');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read\n",
    "\n",
    "Read rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL as a Query Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT *\n",
    "FROM Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT person_first as first, person_last AS last, country_name AS nationality\n",
    "FROM Person \n",
    "INNER JOIN country \n",
    "ON Person.country_id = Country.country_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "UPDATE \n",
    "FROM Person\n",
    "SET person_first = 'Walter' \n",
    "WHERE person_last = 'Alvarez'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * from person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DELETE \n",
    "FROM Person\n",
    "WHERE person_last = 'Alvarez'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * from person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communicating with database without magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('data/dummy.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('select * from Person')\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communicating with database from `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('data/dummy.db')\n",
    "sql = \"\"\"\n",
    "SELECT * \n",
    "FROM Person\n",
    "\"\"\"\n",
    "df = pd.read_sql(sql, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database normalization\n",
    "\n",
    "Database normalization is performed for two main reasons - reduce redundancy and prevent inconsistencies on insert/update/delete. \n",
    "\n",
    "Note: A fully normalized database is in domain-key normal form (DK/NF) if every constraint is a logical consequence of the definition of the candidate key and domains. However, most practical normalization procedures go through a series of steps known as first, second and third normal forms, and ignore potential modification anomalies that may remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Normal Form (1NF)\n",
    "\n",
    "1. Table has a primary key (unique, non-null column that identifies each row)\n",
    "2. No repeating groups of columns\n",
    "3. Each cell contains a single value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No repeating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ann', 'bob', 'charles']\n",
    "grades = [(78,57), (99, 99), (67, 98)]\n",
    "grade1, grade2 = zip(*grades)\n",
    "df = pd.DataFrame(dict(name=names, grade1=grade1, grade2=grade2))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(df, id_vars='name', \n",
    "             var_name='homework', \n",
    "             value_name='grade')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.homework = df.homework.str.extract('.*(\\d+)$')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each column contains a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ann', 'bob', 'charles']\n",
    "grades = [(78,57), (99, 99), (67, 98)]\n",
    "df = pd.DataFrame(dict(name=names, grade=grades))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.explode('grade').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Normal Form (2NF)\n",
    "\n",
    "1. All columns in each row depend fully on candidate keys\n",
    "\n",
    "This can be quite tricky to understand. Look for candidate composite keys that can uniquely identify a row. Then see if the other columns depend on ALL columns of the composite key.\n",
    "\n",
    "In the example below, suppose we have a table for academic books. Note that (publisher, title) is a candidate key. However, headquarters depends only on publisher and not on title, so this violates 2NF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publishers = ['Springer', 'Springer', 'CUB', 'CUP']\n",
    "headquarters = ['Germany', 'Gernamy', 'England', 'England']\n",
    "titles = ['Linear Algebra Done Wrong', \n",
    "          'Undergraduate Algebra',\n",
    "          'Stochastic Modelling of Reaction–Diffusion Processes',\n",
    "          'An Introduction to Stochastic Dynamics']\n",
    "df = pd.DataFrame(dict(publisher=publishers, \n",
    "                       headquarter=headquarters, \n",
    "                       title=titles))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_ids = [0, 0, 1, 1]\n",
    "titles = ['Linear Algebra Done Wrong', \n",
    "          'Undergraduate Algebra',\n",
    "          'Stochastic Modelling of Reaction–Diffusion Processes',\n",
    "          'An Introduction to Stochastic Dynamics']\n",
    "df1 = pd.DataFrame(dict(title=titles, publisher_id=publisher_ids))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publishers = ['Springer', 'CUP']\n",
    "headquarters = ['Germany', 'England']\n",
    "df2 = pd.DataFrame(dict(publisher=publishers, \n",
    "                       headquarter=headquarters))\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Normal Form (3NF)\n",
    "\n",
    "1. No transitive dependencies between non-candidate columns\n",
    "\n",
    "In the table below, both major and major_description depend on the name (or row number), but major_description only depends on name via the major. This is a transitive dependency and violates 3NF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ann', 'bob', 'charles', 'david']\n",
    "ages = [21, 22, 21, 23]\n",
    "majors = ['math', 'stats', 'bio', 'math']\n",
    "major_descriptions = ['Mathematics', 'Statisitcs', 'Biohazards in the University', 'Mathematics']\n",
    "df = pd.DataFrame(dict(name=names, age=ages, major=majors, major_dscription=major_descriptions))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ann', 'bob', 'charles', 'david']\n",
    "ages = [21, 22, 21, 23]\n",
    "major_ids = [0,1,2, 0]\n",
    "df1 = pd.DataFrame(dict(name=names, age=ages, major=major_ids))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors = ['math', 'stats', 'bio']\n",
    "major_descriptions = ['Mathematics', 'Statisitcs', 'Biohazards in the University']\n",
    "df2 = pd.DataFrame(dict(major=majors, description=major_descriptions))\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLTP and OLAP\n",
    "\n",
    "- OLTP\n",
    "    - Normalized schema\n",
    "- OLAP\n",
    "    - Denormalized schema\n",
    "        - Star\n",
    "            - Facts\n",
    "            - Dimensions\n",
    "        - Snowflake \n",
    "        - Generated from OLTP databases by ETL (Extract-Transform-Load) operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalized schemas\n",
    "    \n",
    "- Data lake\n",
    "- Data warehouse\n",
    "- Data mart        \n",
    "        \n",
    "Data marts typically use a star schema that is customized for the analysis needs. For example, the finance department in a hospital may be most interested in Facts about Claims.\n",
    "\n",
    "These schemas are generally designed to reduce the need for complex joins and return queries efficiently. Generally, there is an Extract Transform Load (ETL) script that periodically batch converts data entered into an OLTP database into such a star schema on an OLAP data mart or warehouse.\n",
    "        \n",
    "![img](https://www.researchgate.net/profile/Hugh_Watson3/publication/239823035/figure/fig2/AS:375035886882819@1466426931869/A-Star-Schema-for-Health-Care-courtesy-of-Arthur-Andersen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating ER diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the entitry-relationship diagram (ERd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -m pip install --quiet eralchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from eralchemy import render_er\n",
    "\n",
    "if not os.path.exists('erd_from_sqlalchemy.png'):\n",
    "    render_er('sqlite:///data/dummy.db', 'erd_from_sqlalchemy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness and scaling\n",
    "\n",
    "As the database grows, it may be necessary to scale your system. In vertical scaling, you get a machine with more resources (more disk space, more RAM, more CPUs). This is obviously limited and quickly becomes prohibitively expensive. In horizontal scaling, you add more (commodity) machines to grow. Two concepts important for horizontal scaling are **replication** and **sharding**.\n",
    "\n",
    "In **replication**, you duplicate the entire database over multiple machines. This does not do anything to make your queries faster, but increases robustness since there is no longer a single point of failure.\n",
    "\n",
    "In **sharding** you divide the rows of your tables into partitions that are distributed over different machines. This can improve query efficiency since queries can be run in parallel.\n",
    "\n",
    "Sharing is also known as horizontal partitioning. In vertical partitioning, you split the columns into partitions. Generally for relational databases, vertical partitioning is hard to achieve unless there is some natural domain specific way to logically split the data.\n",
    "\n",
    "Sharding is technically challenging to achieve with relational databases, and the need to perform horizontal scaling as data sets grew exponentially was a major driver in the development of NoSQL systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
